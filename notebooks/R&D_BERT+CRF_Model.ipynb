{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRiAnGo08qAO"
      },
      "source": [
        "# Named Entity Recognition (NER) System R&D\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48ZZZX008qAP"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qq datasets\n",
        "!pip install -qq seqeval"
      ],
      "metadata": {
        "id": "0CmG41c98t8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZl83TAI8qAP",
        "outputId": "0651daac-7fe4-4750-d216-5531897309c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 14041\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 3250\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 3453\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"conll2003\")\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3i0U4Cgo8qAQ",
        "outputId": "ad908795-4ddc-4e55-b634-94740b710adb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': '0',\n",
              " 'tokens': ['EU',\n",
              "  'rejects',\n",
              "  'German',\n",
              "  'call',\n",
              "  'to',\n",
              "  'boycott',\n",
              "  'British',\n",
              "  'lamb',\n",
              "  '.'],\n",
              " 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n",
              " 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n",
              " 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "dataset[\"train\"][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stXqkAbA8qAR"
      },
      "source": [
        "## BERT-CRF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0pXbu-j8qAS"
      },
      "source": [
        "## Data Loading and Processing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, List, Optional\n",
        "from pathlib import Path\n",
        "import logging\n",
        "\n",
        "class NERConfig:\n",
        "    def __init__(\n",
        "        self,\n",
        "        label_types: List[str],\n",
        "        id2label: Dict[int, str],\n",
        "        max_len: int = 128,\n",
        "        data_path: Optional[str | Path] = None,\n",
        "        base_model_path: Optional[str] = None,\n",
        "        models_path: Optional[str | Path] = None,\n",
        "    ):\n",
        "        if isinstance(data_path, str):\n",
        "            data_path = Path(data_path)\n",
        "        self.DATA_PATH = data_path\n",
        "        if isinstance(models_path, str):\n",
        "            self.MODEL_PATH = Path(models_path)\n",
        "        self.BASE_MODEL_PATH = base_model_path or \"bert-base-cased\"\n",
        "        self.LABEL_TYPES = label_types\n",
        "        self.ID2LABEL = id2label\n",
        "        self.LABEL2ID = {label: id for id, label in id2label.items()}\n",
        "        self.MAX_LEN = max_len\n",
        "        self.TRAIN_BATCH_SIZE = 64\n",
        "        self.VALID_BATCH_SIZE = 32\n",
        "        self.EPOCHS = 15\n",
        "        self.OUT_DIM = 768  # bert-base-cased: 768, bert-large-cased: 1024\n",
        "        self.MODEL_PATH = \"./model.pt\"\n",
        "        self.TOKENIZER = transformers.BertTokenizer.from_pretrained(\n",
        "            self.BASE_MODEL_PATH, do_lower_case=False\n",
        "        )\n",
        "        self.logger = logging.getLogger(self.__class__.__name__)"
      ],
      "metadata": {
        "id": "2VTI6ABO9Pak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLoh4EKC8qAS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import transformers\n",
        "\n",
        "LABEL_TYPES = ['X', '[CLS]', '[SEP]', 'O', 'I-LOC', 'B-PER', 'I-PER', 'I-ORG', 'I-MISC', 'B-MISC', 'B-LOC', 'B-ORG']\n",
        "ID2LABEL = {id: label for id, label in enumerate(LABEL_TYPES)}\n",
        "TOKENIZER = transformers.BertTokenizer.from_pretrained(\n",
        "    \"bert-large-cased\", do_lower_case=False\n",
        ")\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ID2LABEL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVZtNdY1nMNS",
        "outputId": "0e178ba7-a221-4750-da31-8890586ebae5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'X',\n",
              " 1: '[CLS]',\n",
              " 2: '[SEP]',\n",
              " 3: 'O',\n",
              " 4: 'I-LOC',\n",
              " 5: 'B-PER',\n",
              " 6: 'I-PER',\n",
              " 7: 'I-ORG',\n",
              " 8: 'I-MISC',\n",
              " 9: 'B-MISC',\n",
              " 10: 'B-LOC',\n",
              " 11: 'B-ORG'}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIqYCxFI8qAT"
      },
      "outputs": [],
      "source": [
        "from typing import List, Dict, Optional\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# from ner_system.config import NERConfig\n",
        "\n",
        "ner_config = NERConfig(\n",
        "    label_types=LABEL_TYPES,\n",
        "    id2label=ID2LABEL,\n",
        "    max_len=128,\n",
        "    base_model_path=\"bert-base-cased\",\n",
        ")\n",
        "\n",
        "\n",
        "class CoNLL2003Document:\n",
        "    \"\"\"\n",
        "    Class to represent a single CoNLL2003 document in its base form.\n",
        "\n",
        "    Supports target labels as integers (if coming from `datasets` library)\n",
        "    or strings (if coming from the \"traditional\" CoNLL2003 format).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        unique_id: int,\n",
        "        tokens: List[str],\n",
        "        ner_tags: List[str] | List[int],\n",
        "    ):\n",
        "        self.unique_id = unique_id\n",
        "        self.tokens = tokens\n",
        "        if isinstance(ner_tags[0], int):\n",
        "            self.ner_tags_str = [ner_config.ID2LABEL[tag] for tag in ner_tags]\n",
        "            self.ner_tags_int = ner_tags\n",
        "        elif isinstance(ner_tags[0], str):\n",
        "            self.ner_tags_int = [ner_config.LABEL2ID[tag] for tag in ner_tags]\n",
        "            self.ner_tags_str = ner_tags\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tokens)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        _token = self.tokens[idx]\n",
        "        _tag = self.ner_tags_str[idx]\n",
        "        return (_token, _tag)\n",
        "\n",
        "    def to_dict(self):\n",
        "        return {\n",
        "            \"unique_id\": self.unique_id,\n",
        "            \"tokens\": self.tokens,\n",
        "            \"ner_tags_str\": self.ner_tags_str,\n",
        "            \"ner_tags_int\": self.ner_tags_int,\n",
        "        }\n",
        "\n",
        "\n",
        "class CoNLL2003Features:\n",
        "    \"\"\"\n",
        "    Class to represent a single CoNLL2003 document in its featureized form.\n",
        "\n",
        "    A result from the `_convert_to_features` method of `NERDataset`.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_ids: List[int],\n",
        "        input_mask: List[int],\n",
        "        token_type_ids: List[int],\n",
        "        crf_mask: List[int],  # CRF() requires specific mask to avoid: ValueError: mask of the first timestep must all be on\n",
        "        predict_mask: List[int],\n",
        "        label_ids: List[int],\n",
        "    ):\n",
        "        self.input_ids = input_ids\n",
        "        self.input_mask = input_mask\n",
        "        self.token_type_ids = token_type_ids\n",
        "        self.crf_mask = crf_mask\n",
        "        self.predict_mask = predict_mask\n",
        "        self.label_ids = label_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-ouAsWP8qAT"
      },
      "outputs": [],
      "source": [
        "class NERDataset:\n",
        "    def __init__(self, data: List[CoNLL2003Document]):\n",
        "        self.data = data\n",
        "        # Set IDs of special tokens\n",
        "        self.CLS = 101\n",
        "        self.SEP = 102\n",
        "        self.PAD = 0\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    @property\n",
        "    def data(self):\n",
        "        return self._data\n",
        "\n",
        "    @data.setter\n",
        "    def data(self, value):\n",
        "        self._data = value\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        _doc = self.data[idx]\n",
        "        _feat = self._convert_to_features(_doc)\n",
        "        return (\n",
        "            _feat.input_ids,\n",
        "            _feat.input_mask,\n",
        "            _feat.token_type_ids,\n",
        "            _feat.crf_mask,\n",
        "            _feat.predict_mask,\n",
        "            _feat.label_ids,\n",
        "        )\n",
        "\n",
        "    def _convert_to_features(self, document: CoNLL2003Document) -> CoNLL2003Features:\n",
        "        # Initializes sequence\n",
        "        _add_label = \"X\"\n",
        "        _tokens = [\"[CLS]\"]\n",
        "        predict_mask = [0]\n",
        "        label_ids = [0]\n",
        "\n",
        "        # Populates sequence as it converts tokens to subwords\n",
        "        for i, tok in enumerate(document.tokens):\n",
        "            subwords = ner_config.TOKENIZER.tokenize(tok)\n",
        "            if not subwords:\n",
        "                subwords = [\"[UNK]\"]\n",
        "            _tokens.extend(subwords)\n",
        "            for j, sub in enumerate(subwords):\n",
        "                if j == 0:\n",
        "                    predict_mask.append(1)\n",
        "                    label_ids.append(ner_config.LABEL2ID[document.ner_tags_str[i]])\n",
        "                else:\n",
        "                    predict_mask.append(0)\n",
        "                    label_ids.append(ner_config.LABEL2ID[_add_label])\n",
        "\n",
        "        # Implement truncation strategy (chops end of sequence)\n",
        "        if len(_tokens) > ner_config.MAX_LEN - 1:\n",
        "            _tokens = _tokens[0: ner_config.MAX_LEN - 1]\n",
        "            predict_mask = predict_mask[0: ner_config.MAX_LEN - 1]\n",
        "            label_ids = label_ids[0: ner_config.MAX_LEN - 1]\n",
        "\n",
        "        # Finalizes sequence\n",
        "        _tokens.append(\"[SEP]\")\n",
        "        predict_mask.append(0)\n",
        "        label_ids.append(0)\n",
        "\n",
        "        # Generates remaining features\n",
        "        input_ids = ner_config.TOKENIZER.convert_tokens_to_ids(_tokens)\n",
        "        input_mask = [1] * len(input_ids)\n",
        "        crf_mask = [1] * len(input_ids)\n",
        "        token_type_ids = [0] * len(input_ids)\n",
        "\n",
        "        # Hard tests\n",
        "        assert len(input_ids) == len(input_mask) == len(crf_mask) == len(token_type_ids) == len(predict_mask) == len(label_ids)\n",
        "\n",
        "        return CoNLL2003Features(\n",
        "            input_ids, input_mask, crf_mask, token_type_ids, predict_mask, label_ids\n",
        "        )\n",
        "\n",
        "    @classmethod\n",
        "    def pad(cls, batch: List[Dict[str, torch.Tensor]]):\n",
        "        _seq_lens = [len(sample[0]) for sample in batch]\n",
        "        _maxlen = np.array(_seq_lens).max()\n",
        "\n",
        "        def _f(x, seqlen):\n",
        "            return [sample[x] + [0] * (seqlen - len(sample[x])) for sample in batch]\n",
        "\n",
        "        input_ids_list = torch.LongTensor(_f(0, ner_config.MAX_LEN))\n",
        "        input_mask_list = torch.LongTensor(_f(1, ner_config.MAX_LEN))\n",
        "        crf_mask_list = torch.ByteTensor(_f(2, ner_config.MAX_LEN))\n",
        "        token_type_ids_list = torch.LongTensor(_f(3, ner_config.MAX_LEN))\n",
        "        predict_mask_list = torch.ByteTensor(_f(4, ner_config.MAX_LEN))\n",
        "        label_ids_list = torch.LongTensor(_f(5, ner_config.MAX_LEN))\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": input_ids_list,\n",
        "            \"input_mask\": input_mask_list,\n",
        "            \"crf_mask\": crf_mask_list,\n",
        "            \"token_type_ids\": token_type_ids_list,\n",
        "            \"predict_mask\": predict_mask_list,\n",
        "            \"label_ids\": label_ids_list\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNJ1SW-R8qAU"
      },
      "outputs": [],
      "source": [
        "def convert_to_conll2003_document(\n",
        "    tokens: List[str],\n",
        "    ner_tags: List[int],\n",
        "    unique_id: int,\n",
        ") -> CoNLL2003Document:\n",
        "    \"\"\"\n",
        "    Converts a single document from the CoNLL2003 dataset to a CoNLL2003Document object.\n",
        "    \"\"\"\n",
        "    return CoNLL2003Document(tokens=tokens, ner_tags=ner_tags, unique_id=unique_id)\n",
        "\n",
        "\n",
        "# _dummy = dataset[\"train\"][:10]\n",
        "# dummy = [\n",
        "#     convert_to_conll2003_document(\n",
        "#         tokens=toks,\n",
        "#         ner_tags=tags,\n",
        "#         unique_id=id,\n",
        "#     )\n",
        "#     for toks, tags, id in zip(_dummy[\"tokens\"], _dummy[\"ner_tags\"], _dummy[\"id\"])\n",
        "# ]\n",
        "# a = NERDataset(dummy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwalYRkf8qAU"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "\n",
        "def prepare_NER_data(dataset: Dataset, split: str = None):\n",
        "    if not split:\n",
        "        ValueError(\"At least one of `train`, `validation` or `test` must be provided.\")\n",
        "\n",
        "    if split not in [\"train\", \"validation\", \"test\"]:\n",
        "        ValueError(\"`split` must be one of `train`, `validation` or `test`.\")\n",
        "\n",
        "    _data = dataset[split]\n",
        "    _docs = [\n",
        "        convert_to_conll2003_document(\n",
        "            tokens=toks,\n",
        "            ner_tags=tags,\n",
        "            unique_id=id,\n",
        "        )\n",
        "        for toks, tags, id in zip(_data[\"tokens\"], _data[\"ner_tags\"], _data[\"id\"])\n",
        "    ]\n",
        "\n",
        "    return NERDataset(_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-M8zRKb8qAU"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_data = prepare_NER_data(dataset, split=\"train\")\n",
        "val_data = prepare_NER_data(dataset, split=\"validation\")\n",
        "test_data = prepare_NER_data(dataset, split=\"test\")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_data,\n",
        "    batch_size=ner_config.TRAIN_BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    collate_fn=NERDataset.pad\n",
        ")\n",
        "valid_loader = DataLoader(\n",
        "    dataset=val_data,\n",
        "    batch_size=ner_config.VALID_BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    collate_fn=NERDataset.pad\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_data,\n",
        "    batch_size=ner_config.VALID_BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    collate_fn=NERDataset.pad\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEd4wr2L8qAU",
        "outputId": "84e313ce-187d-445b-8249-471ba41609cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[  101,   138,  1602,  ...,     0,     0,     0],\n",
            "        [  101,   107,  1109,  ...,     0,     0,     0],\n",
            "        [  101,  1109, 22593,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  101, 10163,  1105,  ...,     0,     0,     0],\n",
            "        [  101, 24890,  9741,  ...,     0,     0,     0],\n",
            "        [  101,  6232,  1496,  ...,     0,     0,     0]], device='cuda:0'), 'input_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'crf_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0', dtype=torch.uint8), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0'), 'predict_mask': tensor([[0, 1, 1,  ..., 0, 0, 0],\n",
            "        [0, 1, 1,  ..., 0, 0, 0],\n",
            "        [0, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 1, 1,  ..., 0, 0, 0],\n",
            "        [0, 1, 0,  ..., 0, 0, 0],\n",
            "        [0, 1, 1,  ..., 0, 0, 0]], device='cuda:0', dtype=torch.uint8), 'label_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 5, 0,  ..., 0, 0, 0],\n",
            "        [0, 3, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')}\n"
          ]
        }
      ],
      "source": [
        "for data in train_loader:\n",
        "    batch = {k: v.to(DEVICE) for k, v in data.items()}\n",
        "    print(batch)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOsuXeRRQo1y",
        "outputId": "947e0594-c2d4-4362-ff8c-ed745a465f39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'input_mask', 'crf_mask', 'token_type_ids', 'predict_mask', 'label_ids'])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMJwPPpO8qAV"
      },
      "source": [
        "### Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Pch_uUT8qAV"
      },
      "outputs": [],
      "source": [
        "import torch.nn as\n",
        "\n",
        "# NOTE: Forked from https://pytorch-crf.readthedocs.io/en/stable/_modules/torchcrf.html#CRF\n",
        "\n",
        "class CRF(nn.Module):\n",
        "    \"\"\"Conditional random field.\n",
        "\n",
        "    This module implements a conditional random field [LMP01]_. The forward computation\n",
        "    of this class computes the log likelihood of the given sequence of tags and\n",
        "    emission score tensor. This class also has `~CRF.decode` method which finds\n",
        "    the best tag sequence given an emission score tensor using `Viterbi algorithm`_.\n",
        "\n",
        "    Args:\n",
        "        num_tags: Number of tags.\n",
        "        batch_first: Whether the first dimension corresponds to the size of a minibatch.\n",
        "\n",
        "    Attributes:\n",
        "        start_transitions (`~torch.nn.Parameter`): Start transition score tensor of size\n",
        "            ``(num_tags,)``.\n",
        "        end_transitions (`~torch.nn.Parameter`): End transition score tensor of size\n",
        "            ``(num_tags,)``.\n",
        "        transitions (`~torch.nn.Parameter`): Transition score tensor of size\n",
        "            ``(num_tags, num_tags)``.\n",
        "\n",
        "\n",
        "    .. [LMP01] Lafferty, J., McCallum, A., Pereira, F. (2001).\n",
        "       \"Conditional random fields: Probabilistic models for segmenting and\n",
        "       labeling sequence data\". *Proc. 18th International Conf. on Machine\n",
        "       Learning*. Morgan Kaufmann. pp. 282–289.\n",
        "\n",
        "    .. _Viterbi algorithm: https://en.wikipedia.org/wiki/Viterbi_algorithm\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_tags: int, batch_first: bool = False) -> None:\n",
        "        if num_tags <= 0:\n",
        "            raise ValueError(f'invalid number of tags: {num_tags}')\n",
        "        super().__init__()\n",
        "        self.num_tags = num_tags\n",
        "        self.batch_first = batch_first\n",
        "        self.start_transitions = nn.Parameter(torch.empty(num_tags))\n",
        "        self.end_transitions = nn.Parameter(torch.empty(num_tags))\n",
        "        self.transitions = nn.Parameter(torch.empty(num_tags, num_tags))\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self) -> None:\n",
        "        \"\"\"Initialize the transition parameters.\n",
        "\n",
        "        The parameters will be initialized randomly from a uniform distribution\n",
        "        between -0.1 and 0.1.\n",
        "        \"\"\"\n",
        "        nn.init.uniform_(self.start_transitions, -0.1, 0.1)\n",
        "        nn.init.uniform_(self.end_transitions, -0.1, 0.1)\n",
        "        nn.init.uniform_(self.transitions, -0.1, 0.1)\n",
        "\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return f'{self.__class__.__name__}(num_tags={self.num_tags})'\n",
        "\n",
        "    def forward(\n",
        "            self,\n",
        "            emissions: torch.Tensor,\n",
        "            tags: torch.LongTensor,\n",
        "            mask: Optional[torch.ByteTensor] = None,\n",
        "            reduction: str = 'sum',\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"Compute the conditional log likelihood of a sequence of tags given emission scores.\n",
        "\n",
        "        Args:\n",
        "            emissions (`~torch.Tensor`): Emission score tensor of size\n",
        "                ``(seq_length, batch_size, num_tags)`` if ``batch_first`` is ``False``,\n",
        "                ``(batch_size, seq_length, num_tags)`` otherwise.\n",
        "            tags (`~torch.LongTensor`): Sequence of tags tensor of size\n",
        "                ``(seq_length, batch_size)`` if ``batch_first`` is ``False``,\n",
        "                ``(batch_size, seq_length)`` otherwise.\n",
        "            mask (`~torch.ByteTensor`): Mask tensor of size ``(seq_length, batch_size)``\n",
        "                if ``batch_first`` is ``False``, ``(batch_size, seq_length)`` otherwise.\n",
        "            reduction: Specifies  the reduction to apply to the output:\n",
        "                ``none|sum|mean|token_mean``. ``none``: no reduction will be applied.\n",
        "                ``sum``: the output will be summed over batches. ``mean``: the output will be\n",
        "                averaged over batches. ``token_mean``: the output will be averaged over tokens.\n",
        "\n",
        "        Returns:\n",
        "            `~torch.Tensor`: The log likelihood. This will have size ``(batch_size,)`` if\n",
        "            reduction is ``none``, ``()`` otherwise.\n",
        "        \"\"\"\n",
        "        self._validate(emissions, tags=tags, mask=mask)\n",
        "        if reduction not in ('none', 'sum', 'mean', 'token_mean'):\n",
        "            raise ValueError(f'invalid reduction: {reduction}')\n",
        "        if mask is None:\n",
        "            mask = torch.ones_like(tags, dtype=torch.uint8)\n",
        "\n",
        "        if self.batch_first:\n",
        "            emissions = emissions.transpose(0, 1)\n",
        "            tags = tags.transpose(0, 1)\n",
        "            mask = mask.transpose(0, 1)\n",
        "\n",
        "        # shape: (batch_size,)\n",
        "        numerator = self._compute_score(emissions, tags, mask)\n",
        "        # shape: (batch_size,)\n",
        "        denominator = self._compute_normalizer(emissions, mask)\n",
        "        # shape: (batch_size,)\n",
        "        llh = numerator - denominator\n",
        "\n",
        "        if reduction == 'none':\n",
        "            return llh\n",
        "        if reduction == 'sum':\n",
        "            return llh.sum()\n",
        "        if reduction == 'mean':\n",
        "            return llh.mean()\n",
        "        assert reduction == 'token_mean'\n",
        "        return llh.sum() / mask.float().sum()\n",
        "\n",
        "    def decode(self, emissions: torch.Tensor,\n",
        "               mask: Optional[torch.ByteTensor] = None) -> List[List[int]]:\n",
        "        \"\"\"Find the most likely tag sequence using Viterbi algorithm.\n",
        "\n",
        "        Args:\n",
        "            emissions (`~torch.Tensor`): Emission score tensor of size\n",
        "                ``(seq_length, batch_size, num_tags)`` if ``batch_first`` is ``False``,\n",
        "                ``(batch_size, seq_length, num_tags)`` otherwise.\n",
        "            mask (`~torch.ByteTensor`): Mask tensor of size ``(seq_length, batch_size)``\n",
        "                if ``batch_first`` is ``False``, ``(batch_size, seq_length)`` otherwise.\n",
        "\n",
        "        Returns:\n",
        "            List of list containing the best tag sequence for each batch.\n",
        "        \"\"\"\n",
        "        self._validate(emissions, mask=mask)\n",
        "        if mask is None:\n",
        "            mask = emissions.new_ones(emissions.shape[:2], dtype=torch.uint8)\n",
        "\n",
        "        if self.batch_first:\n",
        "            emissions = emissions.transpose(0, 1)\n",
        "            mask = mask.transpose(0, 1)\n",
        "\n",
        "        return self._viterbi_decode(emissions, mask)\n",
        "\n",
        "\n",
        "    def _validate(\n",
        "            self,\n",
        "            emissions: torch.Tensor,\n",
        "            tags: Optional[torch.LongTensor] = None,\n",
        "            mask: Optional[torch.ByteTensor] = None) -> None:\n",
        "        if emissions.dim() != 3:\n",
        "            raise ValueError(f'emissions must have dimension of 3, got {emissions.dim()}')\n",
        "        if emissions.size(2) != self.num_tags:\n",
        "            raise ValueError(\n",
        "                f'expected last dimension of emissions is {self.num_tags}, '\n",
        "                f'got {emissions.size(2)}')\n",
        "\n",
        "        if tags is not None:\n",
        "            if emissions.shape[:2] != tags.shape:\n",
        "                raise ValueError(\n",
        "                    'the first two dimensions of emissions and tags must match, '\n",
        "                    f'got {tuple(emissions.shape[:2])} and {tuple(tags.shape)}')\n",
        "\n",
        "        if mask is not None:\n",
        "            if emissions.shape[:2] != mask.shape:\n",
        "                raise ValueError(\n",
        "                    'the first two dimensions of emissions and mask must match, '\n",
        "                    f'got {tuple(emissions.shape[:2])} and {tuple(mask.shape)}')\n",
        "            no_empty_seq = not self.batch_first and mask[0].all()\n",
        "            no_empty_seq_bf = self.batch_first and mask[:, 0].all()\n",
        "            if not no_empty_seq and not no_empty_seq_bf:\n",
        "                raise ValueError('mask of the first timestep must all be on')\n",
        "\n",
        "    def _compute_score(\n",
        "            self, emissions: torch.Tensor, tags: torch.LongTensor,\n",
        "            mask: torch.ByteTensor) -> torch.Tensor:\n",
        "        # emissions: (seq_length, batch_size, num_tags)\n",
        "        # tags: (seq_length, batch_size)\n",
        "        # mask: (seq_length, batch_size)\n",
        "        assert emissions.dim() == 3 and tags.dim() == 2\n",
        "        assert emissions.shape[:2] == tags.shape\n",
        "        assert emissions.size(2) == self.num_tags\n",
        "        assert mask.shape == tags.shape\n",
        "        assert mask[0].all()\n",
        "\n",
        "        seq_length, batch_size = tags.shape\n",
        "        mask = mask.float()\n",
        "\n",
        "        # Start transition score and first emission\n",
        "        # shape: (batch_size,)\n",
        "        score = self.start_transitions[tags[0]]\n",
        "        score += emissions[0, torch.arange(batch_size), tags[0]]\n",
        "\n",
        "        for i in range(1, seq_length):\n",
        "            # Transition score to next tag, only added if next timestep is valid (mask == 1)\n",
        "            # shape: (batch_size,)\n",
        "            score += self.transitions[tags[i - 1], tags[i]] * mask[i]\n",
        "\n",
        "            # Emission score for next tag, only added if next timestep is valid (mask == 1)\n",
        "            # shape: (batch_size,)\n",
        "            score += emissions[i, torch.arange(batch_size), tags[i]] * mask[i]\n",
        "\n",
        "        # End transition score\n",
        "        # shape: (batch_size,)\n",
        "        seq_ends = mask.long().sum(dim=0) - 1\n",
        "        # shape: (batch_size,)\n",
        "        last_tags = tags[seq_ends, torch.arange(batch_size)]\n",
        "        # shape: (batch_size,)\n",
        "        score += self.end_transitions[last_tags]\n",
        "\n",
        "        return score\n",
        "\n",
        "    def _compute_normalizer(\n",
        "            self, emissions: torch.Tensor, mask: torch.ByteTensor) -> torch.Tensor:\n",
        "        # emissions: (seq_length, batch_size, num_tags)\n",
        "        # mask: (seq_length, batch_size)\n",
        "        assert emissions.dim() == 3 and mask.dim() == 2\n",
        "        assert emissions.shape[:2] == mask.shape\n",
        "        assert emissions.size(2) == self.num_tags\n",
        "        assert mask[0].all()\n",
        "\n",
        "        seq_length = emissions.size(0)\n",
        "\n",
        "        # Start transition score and first emission; score has size of\n",
        "        # (batch_size, num_tags) where for each batch, the j-th column stores\n",
        "        # the score that the first timestep has tag j\n",
        "        # shape: (batch_size, num_tags)\n",
        "        score = self.start_transitions + emissions[0]\n",
        "\n",
        "        for i in range(1, seq_length):\n",
        "            # Broadcast score for every possible next tag\n",
        "            # shape: (batch_size, num_tags, 1)\n",
        "            broadcast_score = score.unsqueeze(2)\n",
        "\n",
        "            # Broadcast emission score for every possible current tag\n",
        "            # shape: (batch_size, 1, num_tags)\n",
        "            broadcast_emissions = emissions[i].unsqueeze(1)\n",
        "\n",
        "            # Compute the score tensor of size (batch_size, num_tags, num_tags) where\n",
        "            # for each sample, entry at row i and column j stores the sum of scores of all\n",
        "            # possible tag sequences so far that end with transitioning from tag i to tag j\n",
        "            # and emitting\n",
        "            # shape: (batch_size, num_tags, num_tags)\n",
        "            next_score = broadcast_score + self.transitions + broadcast_emissions\n",
        "\n",
        "            # Sum over all possible current tags, but we're in score space, so a sum\n",
        "            # becomes a log-sum-exp: for each sample, entry i stores the sum of scores of\n",
        "            # all possible tag sequences so far, that end in tag i\n",
        "            # shape: (batch_size, num_tags)\n",
        "            next_score = torch.logsumexp(next_score, dim=1)\n",
        "\n",
        "            # Set score to the next score if this timestep is valid (mask == 1)\n",
        "            # shape: (batch_size, num_tags)\n",
        "            score = torch.where(mask[i].unsqueeze(1), next_score, score)\n",
        "\n",
        "        # End transition score\n",
        "        # shape: (batch_size, num_tags)\n",
        "        score += self.end_transitions\n",
        "\n",
        "        # Sum (log-sum-exp) over all possible tags\n",
        "        # shape: (batch_size,)\n",
        "        return torch.logsumexp(score, dim=1)\n",
        "\n",
        "    def _viterbi_decode(self, emissions: torch.FloatTensor,\n",
        "                        mask: torch.ByteTensor) -> List[List[int]]:\n",
        "        # emissions: (seq_length, batch_size, num_tags)\n",
        "        # mask: (seq_length, batch_size)\n",
        "        assert emissions.dim() == 3 and mask.dim() == 2\n",
        "        assert emissions.shape[:2] == mask.shape\n",
        "        assert emissions.size(2) == self.num_tags\n",
        "        assert mask[0].all()\n",
        "\n",
        "        seq_length, batch_size = mask.shape\n",
        "\n",
        "        # Start transition and first emission\n",
        "        # shape: (batch_size, num_tags)\n",
        "        score = self.start_transitions + emissions[0]\n",
        "        history = []\n",
        "\n",
        "        # score is a tensor of size (batch_size, num_tags) where for every batch,\n",
        "        # value at column j stores the score of the best tag sequence so far that ends\n",
        "        # with tag j\n",
        "        # history saves where the best tags candidate transitioned from; this is used\n",
        "        # when we trace back the best tag sequence\n",
        "\n",
        "        # Viterbi algorithm recursive case: we compute the score of the best tag sequence\n",
        "        # for every possible next tag\n",
        "        for i in range(1, seq_length):\n",
        "            # Broadcast viterbi score for every possible next tag\n",
        "            # shape: (batch_size, num_tags, 1)\n",
        "            broadcast_score = score.unsqueeze(2)\n",
        "\n",
        "            # Broadcast emission score for every possible current tag\n",
        "            # shape: (batch_size, 1, num_tags)\n",
        "            broadcast_emission = emissions[i].unsqueeze(1)\n",
        "\n",
        "            # Compute the score tensor of size (batch_size, num_tags, num_tags) where\n",
        "            # for each sample, entry at row i and column j stores the score of the best\n",
        "            # tag sequence so far that ends with transitioning from tag i to tag j and emitting\n",
        "            # shape: (batch_size, num_tags, num_tags)\n",
        "            next_score = broadcast_score + self.transitions + broadcast_emission\n",
        "\n",
        "            # Find the maximum score over all possible current tag\n",
        "            # shape: (batch_size, num_tags)\n",
        "            next_score, indices = next_score.max(dim=1)\n",
        "\n",
        "            # Set score to the next score if this timestep is valid (mask == 1)\n",
        "            # and save the index that produces the next score\n",
        "            # shape: (batch_size, num_tags)\n",
        "            score = torch.where(mask[i].unsqueeze(1), next_score, score)\n",
        "            history.append(indices)\n",
        "\n",
        "        # End transition score\n",
        "        # shape: (batch_size, num_tags)\n",
        "        score += self.end_transitions\n",
        "\n",
        "        # Now, compute the best path for each sample\n",
        "\n",
        "        # shape: (batch_size,)\n",
        "        seq_ends = mask.long().sum(dim=0) - 1\n",
        "        best_tags_list = []\n",
        "\n",
        "        for idx in range(batch_size):\n",
        "            # Find the tag which maximizes the score at the last timestep; this is our best tag\n",
        "            # for the last timestep\n",
        "            _, best_last_tag = score[idx].max(dim=0)\n",
        "            best_tags = [best_last_tag.item()]\n",
        "\n",
        "            # We trace back where the best last tag comes from, append that to our best tag\n",
        "            # sequence, and trace it back again, and so on\n",
        "            for hist in reversed(history[:seq_ends[idx]]):\n",
        "                best_last_tag = hist[idx][best_tags[-1]]\n",
        "                best_tags.append(best_last_tag.item())\n",
        "\n",
        "            # Reverse the order because we start from the last timestep\n",
        "            # assert len(best_tags) == seq_length, \"length of best_tags: {} != seq_length: {}\".format(len(best_tags), seq_length)\n",
        "            best_tags.reverse()\n",
        "            best_tags_list.append(best_tags)\n",
        "\n",
        "        return best_tags_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RNuERN-8qAV"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import AdamW, Optimizer\n",
        "from torch.optim.lr_scheduler import LRScheduler\n",
        "#from torchcrf import CRF\n",
        "\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "from seqeval.metrics import classification_report, accuracy_score, f1_score\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def filter_sequence_output(sequence_of_tags, input_mask, predict_mask):\n",
        "    batch_size = len(sequence_of_tags)\n",
        "    max_len = ner_config.MAX_LEN\n",
        "    current_len = len(sequence_of_tags[0])\n",
        "\n",
        "    filtered_tags = torch.zeros(\n",
        "        batch_size,\n",
        "        max_len,\n",
        "        dtype=torch.long,\n",
        "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "    )\n",
        "    filtered_input_mask = torch.zeros(\n",
        "        batch_size,\n",
        "        max_len,\n",
        "        dtype=torch.long,\n",
        "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "    )\n",
        "\n",
        "    c = 0\n",
        "    try:\n",
        "        for i in range(batch_size):\n",
        "            jj = -1\n",
        "            for j in range(current_len):\n",
        "                if predict_mask[i][j].item() == 1:\n",
        "                    jj += 1\n",
        "                    filtered_tags[i][jj] = sequence_of_tags[i][j] * input_mask[i][j]\n",
        "                    filtered_input_mask[i][jj] = input_mask[i][j]\n",
        "                    c += 1\n",
        "    except Exception as e:\n",
        "        print(f\"c: {c}\")\n",
        "        print(f\"i: {i}, j: {j}, jj: {jj}\")\n",
        "        print(f\"len sequence_of_tags: {len(sequence_of_tags)}\")\n",
        "        print(f\"len sequence_of_tags[i]: {len(sequence_of_tags[i])}\")\n",
        "        print(f\"predict_mask: {predict_mask.shape}\")\n",
        "        print(f\"filtered_tags: {filtered_tags.shape}\")\n",
        "        print(f\"filtered_input_mask: {filtered_input_mask.shape}\")\n",
        "        raise(e)\n",
        "\n",
        "    return filtered_tags, filtered_input_mask\n",
        "\n",
        "\n",
        "class BERTCRFModel(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_tags: int,\n",
        "        out_dim: int,\n",
        "        batch_first: bool = True,\n",
        "        dropout: float = None,\n",
        "    ):\n",
        "        super(BERTCRFModel, self).__init__()\n",
        "        self.num_tags = num_tags\n",
        "        self.out_dim = out_dim\n",
        "        if dropout:\n",
        "            self.dropout = nn.Dropout(dropout)\n",
        "        self.bert = transformers.BertModel.from_pretrained(\n",
        "            ner_config.BASE_MODEL_PATH, return_dict=False\n",
        "        )\n",
        "        self.linear = nn.Linear(self.out_dim, self.num_tags)\n",
        "        # self.linear.bias.data[0] = 6\n",
        "        self.crf = CRF(num_tags, batch_first=batch_first)\n",
        "        self.logger = logging.getLogger(self.__class__.__name__)\n",
        "        self.logger.info(f\"Initialized BERTCRFModel with the following params: {self.__dict__}\")\n",
        "\n",
        "    def forward(\n",
        "        self, input_ids, input_mask, crf_mask, token_type_ids, predict_mask, label_ids\n",
        "    ):\n",
        "        o1, _ = self.bert(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=input_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "        )\n",
        "        if self.dropout:\n",
        "            o1 = self.dropout(o1)\n",
        "        # Take encoded output and compute its emission matrices\n",
        "        # print(o1.shape)\n",
        "        # print(model.linear.weight.shape)\n",
        "        emissions = self.linear(o1)\n",
        "\n",
        "        # Compute the negative log-likelihood for the CRF\n",
        "        crf_mask[0].fill_(1)  # Mitigates: ValueError: mask of the first timestep must all be on\n",
        "        assert crf_mask[:, 0].all()\n",
        "\n",
        "        print(f\"inputs_ids: {input_ids.shape}\")\n",
        "        print(f\"predict_mask: {predict_mask.shape}\")\n",
        "        print(f\"label_ids: {label_ids.shape}\")\n",
        "        print(f\"emissions: {emissions.shape}\")\n",
        "\n",
        "        log_likelihood = self.crf(\n",
        "            emissions=emissions,\n",
        "            tags=label_ids,\n",
        "            mask=crf_mask.bool(),\n",
        "            reduction=\"mean\"\n",
        "        )\n",
        "\n",
        "        # Decode the most likely sequence of tags\n",
        "        sequence_of_tags = self.crf.decode(emissions, mask=crf_mask.bool())\n",
        "\n",
        "        print(f\"sequence_of_tags: {sequence_of_tags}\")\n",
        "\n",
        "        # Retrieve the target tag given the input and predicted masks\n",
        "        pred_tags, filtered_mask = filter_sequence_output(\n",
        "            sequence_of_tags, input_mask, predict_mask\n",
        "        )\n",
        "        loss = -1 * log_likelihood\n",
        "\n",
        "        return pred_tags, label_ids, filtered_mask, loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YseFcoc38qAW"
      },
      "outputs": [],
      "source": [
        "def train(\n",
        "    dataloader: DataLoader,\n",
        "    model: BERTCRFModel,\n",
        "    optimizer: Optimizer,\n",
        "    device: torch.device,\n",
        "    scheduler: Optional[LRScheduler] = None,\n",
        "):\n",
        "    model.train()\n",
        "\n",
        "    final_loss = 0\n",
        "    y_gold = []\n",
        "    y_pred = []\n",
        "\n",
        "    for data in tqdm(dataloader, total=len(dataloader)):\n",
        "        batch = {k: v.to(DEVICE) for k, v in data.items()}\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        pred_tags, gold_tags, mask, loss = model(**batch)\n",
        "        # print(f\"pred_tags: {pred_tags.shape}\")\n",
        "        # print(f\"gold_tags: {gold_tags.shape}\")\n",
        "        # print(f\"mask: {mask.shape}\")\n",
        "        # print(f\"loss: {loss}\")\n",
        "\n",
        "        mapped_gold = [\n",
        "            ner_config.ID2LABEL[item]\n",
        "            for item in torch.flatten(mask * pred_tags).detach().cpu().tolist()\n",
        "        ]\n",
        "        mapped_pred = [\n",
        "            ner_config.ID2LABEL[item]\n",
        "            for item in torch.flatten(mask * gold_tags).detach().cpu().tolist()\n",
        "        ]\n",
        "        y_gold.append(mapped_gold)\n",
        "        y_pred.append(mapped_pred)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        final_loss += loss.item()\n",
        "\n",
        "    return final_loss / len(dataloader), f1_score(y_gold, y_pred)\n",
        "\n",
        "\n",
        "def evaluate(dataloader: DataLoader, model: BERTCRFModel, device: torch.device):\n",
        "    model.eval()\n",
        "\n",
        "    final_loss = 0\n",
        "    y_gold = []\n",
        "    y_pred = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm(dataloader, total=len(dataloader)):\n",
        "            batch = {k: v.to(DEVICE) for k, v in data.items()}\n",
        "\n",
        "            pred_tags, gold_tags, mask, loss = model(**batch)\n",
        "            mapped_target = [\n",
        "                ner_config.ID2LABEL[item]\n",
        "                for item in torch.flatten(mask * gold_tags).detach().cpu().tolist()\n",
        "            ]\n",
        "            mapped_output = [\n",
        "                ner_config.ID2LABEL[item]\n",
        "                for item in torch.flatten(mask * pred_tags).detach().cpu().tolist()\n",
        "            ]\n",
        "            y_gold.append(mapped_target)\n",
        "            y_pred.append(mapped_output)\n",
        "\n",
        "            final_loss += loss.item()\n",
        "\n",
        "    return final_loss / len(dataloader), f1_score(y_gold, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktVJlrdH8qAW"
      },
      "outputs": [],
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = BERTCRFModel(\n",
        "    num_tags=len(ner_config.LABEL_TYPES),\n",
        "    out_dim=ner_config.OUT_DIM,\n",
        "    batch_first=False,\n",
        "    dropout=0.1,\n",
        ").to(DEVICE)\n",
        "\n",
        "optim_parameters = [\n",
        "    {\"params\": model.bert.parameters(), \"lr\": 5e-5},\n",
        "    {\"params\": model.linear.parameters(), \"lr\": 1e-3},\n",
        "    {\"params\": model.crf.parameters(), \"lr\": 1e-3},\n",
        "]\n",
        "optimizer = AdamW(optim_parameters, weight_decay=0.01)\n",
        "\n",
        "_num_train_steps = (\n",
        "    dataset[\"train\"].num_rows / ner_config.TRAIN_BATCH_SIZE * ner_config.EPOCHS\n",
        ")\n",
        "num_train_steps = int(_num_train_steps)\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer, num_warmup_steps=num_train_steps*0.1, num_training_steps=num_train_steps\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "id": "eShhKVF88qAW",
        "outputId": "fa81995c-f8ce-47fa-b07e-1230d26ae3e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/220 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs_ids: torch.Size([64, 128])\n",
            "predict_mask: torch.Size([64, 128])\n",
            "label_ids: torch.Size([64, 128])\n",
            "emissions: torch.Size([64, 128, 12])\n",
            "sequence_of_tags: [[11, 5, 2, 5, 4, 5, 0, 5, 4, 5, 11, 4, 10, 5, 8, 5, 4, 5, 4, 0, 5, 8, 8, 7, 4, 4, 8, 8, 4, 5, 4, 5, 4, 5, 4, 0, 11, 5, 8, 8, 8, 8, 4, 4, 5, 8, 2, 5, 8, 5, 0, 5, 5, 4, 5, 4, 4, 11, 5, 5, 4, 4, 4, 5], [5, 4, 1, 2, 1, 0, 11, 4, 4, 1, 7, 0, 11, 5, 4, 1, 5, 3, 5, 1, 4, 3, 8, 7, 3, 8, 8, 4, 1, 3, 4, 5, 1, 2, 1, 5, 1, 2, 7, 5, 1, 1, 2, 5, 8, 0, 11, 8, 0, 8, 0, 5, 1, 5, 9, 4, 5, 3, 5, 1, 4, 4, 5, 1], [8, 8, 2, 8, 1, 7, 0, 4, 3, 2, 7, 7, 6, 11, 8, 7, 11, 7, 11, 8, 8, 7, 11, 8, 7, 8, 7, 8, 8, 2, 8, 8, 7, 7, 8, 2, 8, 11, 2, 1, 7, 11, 7, 11, 7, 8, 7, 8, 8, 2, 8, 8, 11, 7, 7, 8, 7, 11, 7, 7, 11, 7, 7, 11], [7, 11, 1, 7, 8, 2, 7, 11, 8, 7, 8, 7, 7, 11, 1, 7, 1, 2, 8, 7, 6, 3, 2, 1, 7, 5, 1, 7, 8, 8, 7, 3, 7, 8, 8, 2, 1, 3, 2, 1, 7, 6, 7, 7, 8, 7, 7, 11, 7, 4, 8, 1, 11, 1, 7, 8, 7, 8, 7, 11, 8, 7, 11, 7], [11, 1, 7, 8, 7, 1, 1, 7, 8, 2, 7, 11, 7, 5, 3, 8, 8, 7, 7, 8, 7, 11, 8, 4, 7, 7, 0, 6, 11, 11, 7, 1, 7, 7, 8, 7, 7, 1, 2, 7, 8, 7, 7, 0, 7, 0, 8, 7, 11, 7, 8, 7, 8, 7, 7, 11, 7, 11, 7, 8, 7, 4, 11], [11, 7, 2, 8, 11, 7, 8, 7, 11, 2, 7, 3, 7, 11, 11, 7, 3, 11, 11, 8, 2, 1, 2, 1, 7, 8, 7, 8, 7, 1, 7, 4, 7, 7, 2, 9, 9, 11, 7, 11, 7, 7, 11, 7, 11, 7, 3, 7, 11, 7, 7, 11, 7, 7, 0, 7, 11, 11, 7, 9, 6, 7, 4], [6, 6, 4, 1, 7, 11, 8, 8, 7, 7, 11, 8, 7, 8, 11, 7, 4, 9, 6, 7, 0, 11, 7, 1, 3, 8, 7, 1, 7, 11, 7, 3, 8, 7, 1, 1, 1, 11, 7, 1, 7, 11, 7, 3, 8, 7, 7, 7, 7, 7, 11, 7, 8, 7, 1, 8, 7, 8, 7, 8, 7, 5], [7, 7, 11, 8, 11, 7, 1, 7, 1, 7, 11, 8, 8, 7, 3, 7, 7, 7, 11, 8, 9, 3, 0, 11, 8, 8, 8, 0, 8, 7, 7, 4, 7, 11, 1, 1, 1, 5, 3, 11, 7, 11, 4, 7, 8, 7, 11, 7, 11, 2, 8, 7, 11, 7, 11, 8, 7, 11, 7, 8, 7], [11, 7, 2, 8, 7, 8, 8, 7, 1, 7, 7, 8, 7, 1, 7, 7, 9, 9, 1, 7, 11, 2, 7, 0, 8, 8, 1, 9, 7, 11, 7, 9, 7, 4, 7, 7, 7, 7, 7, 7, 11, 8, 8, 7, 8, 7, 3, 7, 11, 11, 8, 8, 11, 11, 5, 8, 7, 7, 6, 8], [11, 1, 1, 7, 8, 7, 7, 8, 11, 7, 11, 1, 8, 7, 11, 11, 8, 8, 8, 7, 5, 8, 7, 7, 8, 7, 1, 7, 11, 11, 8, 1, 7, 8, 8, 8, 8, 8, 7, 1, 7, 8, 7, 7, 11, 7, 11, 11, 11, 8, 7, 7, 8, 7, 8], [8, 7, 6, 3, 8, 7, 11, 7, 8, 7, 7, 8, 7, 4, 1, 5, 7, 7, 7, 8, 7, 8, 8, 8, 7, 7, 0, 6, 8, 7, 11, 1, 7, 2, 8, 8, 8, 8, 2, 8, 6, 7, 11, 11, 7, 11, 7, 2, 8, 7, 11, 7, 8, 7, 7], [8, 1, 6, 11, 7, 2, 7, 7, 11, 8, 7, 11, 7, 7, 8, 8, 7, 7, 8, 7, 6, 1, 2, 7, 11, 7, 7, 7, 8, 8, 7, 4, 7, 7, 1, 1, 1, 1, 7, 7, 7, 11, 6, 6, 6, 1, 7, 11, 11, 1], [2, 8, 8, 8, 7, 11, 7, 2, 10, 7, 8, 7, 7, 11, 7, 7, 8, 8, 8, 7, 8, 8, 2, 7, 0, 3, 3, 3, 7, 7, 1, 2, 2, 8, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8], [2, 8, 8, 8, 7, 2, 7, 7, 11, 2, 2, 5, 1, 7, 11, 11, 8, 7, 10, 4, 7, 1, 7, 7, 7, 8, 8, 8, 7, 7, 11, 7, 7, 8, 7, 7, 7, 7, 11, 7, 7, 7, 7, 0], [7, 3, 3, 8, 7, 8, 7, 11, 7, 8, 8, 8, 7, 8, 11, 11, 8, 8, 11, 7, 8, 8, 8, 8, 8, 7, 7, 7, 7, 7, 0, 8, 7, 7, 1, 1, 1, 1, 1, 7, 7, 5], [8, 7, 3, 8, 9, 11, 7, 11, 7, 8, 8, 8, 7, 7, 8, 8, 8, 8, 7, 4, 2, 2, 2, 1, 2, 7, 7, 7, 8, 8, 8, 8, 2, 7, 3, 7, 3, 7, 3, 2, 11], [8, 11, 11, 1, 7, 2, 7, 11, 7, 11, 11, 11, 7, 8, 7, 11, 7, 7, 11, 7, 8, 8, 7, 7, 7, 1, 1, 1, 7, 7, 4, 4, 11, 2, 7, 7, 7, 7, 7, 8, 3], [7, 11, 11, 6, 7, 11, 2, 11, 7, 8, 8, 8, 8, 8, 8, 8, 7, 7, 11, 8, 9, 9, 2, 2, 7, 11, 11, 11, 8, 8, 7, 7, 3, 7, 8, 8, 8, 11], [11, 7, 7, 7, 7, 11, 7, 11, 7, 11, 11, 11, 7, 8, 8, 8, 8, 8, 8, 7, 8, 8, 8, 8, 7, 11, 11, 11, 11, 11, 11, 7, 8, 7, 8], [7, 11, 7, 11, 7, 11, 8, 8, 7, 8, 8, 8, 8, 8, 7, 7, 3, 3, 3, 8, 8, 8, 8, 8, 8, 3, 3, 3, 8, 8, 7, 0, 6], [11, 5, 5, 5, 5, 7, 8, 7, 3, 8, 8, 8, 8, 7, 11, 11, 8, 8, 8, 8, 2, 2, 2, 2, 2, 8, 8, 8, 8, 8], [0, 8, 8, 8, 8, 8, 8, 7, 7, 8, 8, 8, 7, 7, 8, 8, 4, 4, 4, 7, 9, 9, 9, 9, 9, 1, 1, 1, 1, 2], [11, 8, 8, 8, 8, 8, 1, 7, 3, 2, 2, 2, 8, 7, 11, 11, 1, 1, 1, 7, 8, 8, 8, 8, 8, 8, 8, 8, 7], [8, 8, 8, 8, 7, 11, 7, 11, 8, 7, 8, 7, 8, 7, 8, 8, 3, 3, 3, 3, 8, 8, 8, 8, 8, 8, 8, 7], [0, 1, 2, 1, 2, 4, 8, 2, 1, 1, 6, 1, 7, 8, 7, 7, 2, 7, 2, 7, 0, 0, 0, 0, 0, 0, 8], [7, 8, 8, 8, 8, 8, 8, 2, 7, 8, 8, 8, 7, 2, 8, 8, 10, 10, 10, 7, 8, 8, 8, 8, 8, 6], [8, 8, 8, 8, 8, 7, 9, 8, 8, 8, 8, 8, 8, 7, 6, 0, 6, 0, 6, 0, 2, 2, 2, 8], [8, 2, 2, 2, 2, 8, 8, 11, 7, 8, 8, 8, 11, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [8, 8, 8, 8, 8, 8, 7, 7, 9, 7, 8, 7, 0, 8, 8, 7, 8, 7, 8, 7, 8, 7], [8, 7, 7, 7, 7, 4, 1, 2, 8, 8, 8, 8, 8, 11, 7, 7, 7, 7, 7, 8], [7, 8, 8, 8, 8, 7, 11, 7, 7, 11, 11, 11, 11, 7, 7, 7, 7, 7], [8, 6, 6, 6, 6, 7, 11, 7, 7, 8, 8, 8, 8, 8, 8, 1], [8, 8, 8, 8, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 7], [7, 8, 8, 8, 8, 8, 8, 11, 11, 2, 2, 2, 2, 8, 7], [8, 8, 8, 8, 8, 7, 7, 7, 7, 11, 11, 11, 11, 7, 7], [8, 8, 8, 8, 8, 7, 8, 7, 7, 8, 8, 8, 8, 8, 6], [7, 8, 8, 8, 8, 7, 11, 7, 7, 8, 8, 8, 8, 7, 8], [11, 8, 8, 8, 8, 2, 6, 7, 7, 2, 5, 2, 8], [8, 2, 2, 2, 2, 9, 9, 2, 2, 2, 2, 2], [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [11, 8, 8, 8, 8, 8, 8, 8, 8], [11, 11, 11, 11, 11, 11, 11, 8], [8, 8, 8, 8, 8, 11, 11, 11], [8, 7, 8, 7, 8, 7, 2], [8, 8, 8, 8, 8, 1], [10, 10, 10, 7, 11], [8, 8, 8, 8, 11], [7, 7, 7, 7, 4], [8, 8, 8, 8, 8], [8, 8, 8, 7], [7, 11, 7, 0], [8, 8, 8, 7], [11, 11, 11, 6], [11, 11, 11, 11], [11, 11, 11, 7], [11, 7, 8], [11, 11, 7], [8, 8, 8], [8, 8, 8], [8, 8, 7], [8, 8, 7], [8, 8, 7], [8], [8], [7], [7], [8], [11], [11], [11], [11], [11], [11], [11], [8], [8], [8], [8], [8], [7], [8], [0], [7], [7], [0], [8], [11], [8], [7], [8], [6], [8], [8], [7], [7], [8], [7], [7], [7], [11], [8], [7], [11], [11], [0], [7], [0], [0], [8], [7], [8], [7], [8], [7], [7], [7], [7], [8], [11], [7], [7], [7], [11], [11], [7], [8], [8], [8]]\n",
            "c: 293\n",
            "i: 13, j: 46, jj: 34\n",
            "len sequence_of_tags: 128\n",
            "len sequence_of_tags[i]: 44\n",
            "predict_mask: torch.Size([64, 128])\n",
            "filtered_tags: torch.Size([128, 128])\n",
            "filtered_input_mask: torch.Size([128, 128])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-e0d08875b453>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mner_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     train_loss, train_f1 = train(\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mdataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-ff0991437ad3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, optimizer, device, scheduler)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mpred_tags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold_tags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;31m# print(f\"pred_tags: {pred_tags.shape}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# print(f\"gold_tags: {gold_tags.shape}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-1944786773c7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, input_mask, crf_mask, token_type_ids, predict_mask, label_ids)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;31m# Retrieve the target tag given the input and predicted masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         pred_tags, filtered_mask = filter_sequence_output(\n\u001b[0m\u001b[1;32m    119\u001b[0m             \u001b[0msequence_of_tags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         )\n",
            "\u001b[0;32m<ipython-input-19-1944786773c7>\u001b[0m in \u001b[0;36mfilter_sequence_output\u001b[0;34m(sequence_of_tags, input_mask, predict_mask)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"filtered_tags: {filtered_tags.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"filtered_input_mask: {filtered_input_mask.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfiltered_tags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_input_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-1944786773c7>\u001b[0m in \u001b[0;36mfilter_sequence_output\u001b[0;34m(sequence_of_tags, input_mask, predict_mask)\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mpredict_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                     \u001b[0mjj\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                     \u001b[0mfiltered_tags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence_of_tags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minput_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m                     \u001b[0mfiltered_input_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                     \u001b[0mc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "\n",
        "best_loss = np.inf\n",
        "for epoch in range(ner_config.EPOCHS):\n",
        "    train_loss, train_f1 = train(\n",
        "        dataloader=train_loader,\n",
        "        model=model,\n",
        "        optimizer=optimizer,\n",
        "        scheduler=scheduler,\n",
        "        device=DEVICE\n",
        "      )\n",
        "    val_loss, val_f1 = evaluate(\n",
        "        dataloader=valid_loader,\n",
        "        model=model,\n",
        "        device=DEVICE\n",
        "      )\n",
        "    print(f\"Train loss = {train_loss} Valid loss = {val_loss} \")\n",
        "    print(f\"Train f1_score = {train_f1} Valid f1_score = {val_f1} \")\n",
        "    if val_loss < best_loss:\n",
        "        torch.save(model.state_dict(), ner_config.MODEL_PATH)\n",
        "        best_loss = val_loss\n",
        "\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b2Y-g1WJsyGH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}